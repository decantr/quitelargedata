\documentclass{article}

\usepackage{graphicx,parskip,bibunits,appendix,float}
\usepackage[ruled] {algorithm2e}
\usepackage{url,amsmath,amssymb,fancybox,listings,pdfpages,caption,multicol,datetime,rotating, booktabs}
\usepackage[pagebackref=false,pdffitwindow=true]{hyperref}

\setlength{\textwidth}{6.5in} 
\setlength{\textheight}{9in}
\setlength{\oddsidemargin}{0in} 
\setlength{\evensidemargin}{0in}
\setlength{\topmargin}{-1.5cm}
\setlength{\parindent}{0cm}
\hypersetup{
  colorlinks   = true, %Colours links instead of ugly boxes
  urlcolor     = blue, %Colour for external hyperlinks
  linkcolor    = blue, %Colour of internal links
  citecolor   = red %Colour of citations
}

\begin{document}
\SweaveOpts{concordance=TRUE}

\title{Coursework (CM3111) \\ Big Data Analytics}
\author{Shaw Eastwood, \href{mailto:s.eastwood@rgu.ac.uk}{s.eastwood@rgu.ac.uk}}

\maketitle

\section{Introduction}
\section{Data Exploration}
\subsection{Dataset Choice}
For the dataset I opted to use the Mushroom Classifiction dataset provided by UCI Machine Learing on Kaggle\footnote{\href{https://www.kaggle.com/uciml/mushroom-classification/}{https://www.kaggle.com/uciml/mushroom-classification/}}. I chose this dataset because of its potential practical application in predicting the edibility of a mushroom merely based on characteristic. This dataset was also featured on Kaggle and came with a very high number of reccomendations. The size of the dataset also made it a suitible choice it was a managable size with a high variance in the attributes.
\subsection{Technology Platform}
For this particular dataset, there is little merit to be gained from using Hadoop as the dataset is of a reasonable size. 
\subsection{Problem Statement \& Data Exploration}

\subsection{Pre-proccessing}
\section{Modelling / Classification}
\section{Improving Performance}
\section{Reproducing Results}


\end{document}